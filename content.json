{"meta":{"title":"Hexo","subtitle":"","description":"","author":"xnf","url":"https://github.com/vacuum-cup/vacuum-cup.github.io","root":"/"},"pages":[{"title":"[404]","date":"2022-11-15T13:26:07.499Z","updated":"2022-11-15T13:26:07.499Z","comments":true,"path":"404.html","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/404.html","excerpt":"","text":"页面走丢了~"},{"title":"About","date":"2022-11-15T07:16:27.000Z","updated":"2022-11-15T13:24:00.378Z","comments":true,"path":"about/index.html","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/about/index.html","excerpt":"","text":"隐姓埋名的小脑斧"}],"posts":[{"title":"pytorch-矩阵乘法运算","slug":"pytorch-矩阵乘法运算","date":"2023-04-06T03:50:36.000Z","updated":"2023-04-06T04:01:50.168Z","comments":true,"path":"2023/04/06/pytorch-矩阵乘法运算/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2023/04/06/pytorch-%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E8%BF%90%E7%AE%97/","excerpt":"","text":"pytorch中矩阵乘法 @运算，*运算，torch.mul(), torch.mm(), torch.mv(), tensor.t() @ 和 *代表矩阵的两种相乘方式：@表示常规的数学上定义的矩阵相乘；*表示两个矩阵对应位置处的两个元素相乘。 x.dot(y): 向量乘积,x，y均为一维向量。 *和torch.mul()等同:表示相同shape矩阵点乘，即对应位置相乘，得到矩阵有相同的shape。 @和torch.mm(a, b)等同：正常矩阵相乘，要求a的列数与b的行数相同。 torch.mv(X, w0):是矩阵和向量相乘.第一个参数是矩阵，第二个参数只能是一维向量,等价于X乘以w0的转置 Y.t():矩阵Y的转置。 参考： (62条消息) pytorch中的矩阵乘法：函数mul,mm,mv以及 @运算 和 *运算_pytorch 矩阵点乘_柏常青的博客-CSDN博客","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"numpy部分方法","slug":"numpy部分方法","date":"2023-03-03T13:03:17.000Z","updated":"2023-03-03T13:10:39.474Z","comments":true,"path":"2023/03/03/numpy部分方法/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2023/03/03/numpy%E9%83%A8%E5%88%86%E6%96%B9%E6%B3%95/","excerpt":"","text":"Numpy 方法 记录部分numpy方法 np.where() np.where(condition,x,y)当where内有三个参数时，第一个参数表示条件，当条件成立时where方法返回x，当条件不成立时where返回y np.where(condition) 当where内只有一个参数时，那个参数表示条件，当条件成立时，where返回的是每个符合condition条件元素的坐标,返回的是以元组的形式 只展示第二种用法 12345import numpy as np #用法二a = np.array([2,4,6,8,10])#只有一个参数表示条件的时候np.where(a &gt; 5) 1(array([2, 3, 4]),)","categories":[{"name":"numpy","slug":"numpy","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/numpy/"}],"tags":[]},{"title":"Python-可变参数-传入参数","slug":"Python-可变参数-传入参数","date":"2023-02-23T01:14:42.000Z","updated":"2023-02-23T01:26:10.721Z","comments":true,"path":"2023/02/23/Python-可变参数-传入参数/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2023/02/23/Python-%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0-%E4%BC%A0%E5%85%A5%E5%8F%82%E6%95%B0/","excerpt":"","text":"1. 可变参数 （*参数，**参数） *参数是收集所有未匹配的位置参数组成一个tuple对象，局部变量args指向 该tuple对象 **参数 收集所有未匹配的关键字参数组成一个dict参数，局部变量kwargs 指向该dict对象 12def test(*args,**kwargs): pass 2. 传入参数 （*参数，**参数） *参数用于解包tuple对象的每个元素，作为一个一个的位置参数传入到函数中 **参数用于解包dict对象的每个元素，作为一个一个的关键字参数传入到函数中 1234567891011my_tuple = (&quot;wang&quot;,&quot;yuan&quot;,&quot;wai&quot;) temp(*my_tuple)#---等同于---#temp(&quot;wangyuan&quot;,&quot;yuan&quot;,&quot;wai&quot;)my_dict = &#123;&quot;name&quot;:&quot;wangyuanwai&quot;,&quot;age&quot;:32&#125; temp(**my_dict)#----等同于----#temp(name=&quot;wangyuanwai&quot;,age=32) 参考文章： (54条消息) Python之可变参数，*参数，**参数，以及传入*参数，**参数解包，*args，**kwargs的理解_叫我王员外就行的博客-CSDN博客","categories":[{"name":"Python","slug":"Python","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Python/"}],"tags":[]},{"title":"小样本学习-关系抽取","slug":"小样本学习-关系抽取","date":"2023-01-02T02:11:57.000Z","updated":"2023-02-13T02:17:22.017Z","comments":true,"path":"2023/01/02/小样本学习-关系抽取/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2023/01/02/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0-%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/","excerpt":"","text":"小样本学习综述 论文 随着大数据时代的到来,深度学习模型已经在图像分类、文本分类等任务中取得了先进成果。但深度学习模型的成功,很大程度上依赖于大量训练数据。而在现实世界的真实场景中，某些类别只有少量数据或少量标注数据，而对无标签数据进行标注将会消耗大量的时间和人力。 本文将小样本学习分为三类：模型微调、数据增强、迁移学习 graph TD 1(小样本学习) 2.1(模型微调) 2.2(数据增强) 2.3(迁移学习) 1==>2.1 1==>2.2 1==>2.3 2.1-.问题.->模型过拟合-.应对.->数据增强 3.1(基于无标签数据) 3.2(基于数据合成) 3.3(基于特征增强) 2.2-->3.1 2.2-->3.2 2.2-->3.3 3.4(基于度量学习) 3.5(基于元学习) 3.6(基于图神经网络) 2.3-->3.4 2.3--根据学习框架-->3.5 2.3-->3.6 基本分类 1. 基于模型微调的小样本学习 在大规模数据上预训练模型，在目标小样本数据集上对神经网络模型的全连接层或者顶端几层进行参数微调，得到微调后的模型。 2018年，ULMFit微调语言模型：该模型分为 3 个阶段:(1) 语言模型预训练;(2) 语言模型微调;(3) 分类器微调.该模型的创新点在于改变学习速率来微调语言模型。主要体现在： ULMFit 中,语言模型的每一层学习速率均不相同.模型底 层表示普遍特征,这些特征不需要很大调整,所以学习速率较慢;而高层特征更具有独特性,更能体现 出任务和数据的独有特征,于是高层特征需要用更大的学习速率学习. 对于模型中的同一层,当迭代次数变化时,自身学习率也会相应地产生变化.作者提出了斜三角学习 率的概念,当迭代次数从 0 开始增加时,学习速率逐渐变大;当迭代次数增长到某个固定值时,此时已 经学习到了足够知识,固定值之后的学习率又开始逐步下降 2019年，另一种微调模型：主要包含以下几个机制:(1) 在小样本类别上再训练的过程使用更低的学习率;(2) 在微调阶段使用自适应的梯度优化器;3) 当源数据集和目标数据集之间存在较大差异性时,可以通过调整整个网络来实现. 问题： 基于模型微调的方法较简单,但是在真实场景中,因为少量数据并不能很好地反映大量数据的真实分布情况,采用模型微调的方法会导致模型在目标数据集上过拟合。 2. 基于数据增强的小样本学习 小样本学习的根本问题在于样本量过少，从而导致样本多样性变低。在数据量有限的情况下，可以通过数据增强(data augmentation)来提高样本多样性。数据增强指借助辅助数据或辅助信息,对原有的小样本数据集进行数据扩充或特征增强.数据扩充是向原有数据集添加新的数据,可以是无标签数据或者合成的带标签数据;特征增强是在原样本的特征空间中添加便于分类的特征,增加特征多样性. 2.1 基于无标签数据 利用无标签数据对小样本数据进行扩充 半监督学习 直推式学习: .直推式学习假设未标注数据是测试数据,目的是在这些未标记数 据上取得最佳泛化能力 2.2 基于数据合成的方法 小样本类别合成新的带标签数据来扩充训练数据 2.3 基于特性增强的方法 通过增强样本特征空间来提高样本的多样性,因为小样本学习的一个关键是如何得到一个泛化性好的特征提取器 2.4 小结 通过梳理基于数据增强的小样本学习模型的研究进展,可以思考未来的两个改进方向. 更好地利用无标注数据:：由于真实世界中存在着大量的无标注数据,不利用这些数据会损失很多信息,更好、更合理地使用无标注数据,是一个非常重要的改进方向. 更好地利用辅助特征：小样本学习中,由于样本量过少导致特征多样性降低.为提高特征多样性,可利用辅助数据集或者辅助属性进行特征增强,从而帮助模型更好地提取特征来提升分类的准确率. 3. 基于迁移学习的小样本学习 迁移学习：利用旧知识来学习新知识,主要目标是将已经学会的知识很快地迁移到一个新的领域中 3.1 度量学习 通过计算待分类样本和已知分类样本之间的距离,找到邻近类别来确定待分类样本的分类结果。基于度量学习方法的通用流程具有两个模块:嵌入模块和度量模块,将样本通过嵌入模块嵌入向量空间,再根据度量模块给出相似度得分. 将度量学习的框架应用到小样本学习上,顾名思义,就是通 过计算待分类样本和已知分类样本之间的距离,找到邻近类别来确定待分类样本的分类结果. 3.2 基于元学习的方法 元学习的目的是让模型获得一种学习能力，这种学习能力可以让模型自动学习到一 些元知识。元知识指在模型训练过程之外可以学习到的知识，比如模型的超参数、神经网络的初始参数、神经网络的结构和优化器等。 在小样本学习中,元学习具体指从大量的先验任务中学习到元知识,利用以往的先验 知识来指导模型在新任务(即小样本任务)中更快地学习. 元学习在少样本学习方向上主要是优化在假设空间寻找最优参数的策略，主要包括两种方式： 寻找一个合适的初始参数。此类方法即meta-representation，经典方法就是模型无关的元学习方法（MAML 其核心思想在于寻找一个模型的初始值，使得该模型能在新任务的少量训练数据上进行快速学习）。 学习一个优化器。此种策略聚焦于学习一个优化器来直接输出参数更新。 3.3 基于图神经网络的方法 图神经网络是一种基于深度学习的处理图领域信息的模型,由于其较好的性能和可解释性,它最近已成为一种广泛应用的图分析方法。 小样本学习方法优缺点对比 少样本关系抽取 少样本关系抽取任务的目标是通过利用极少量的标注数据训练（或Fine-Tuning）模型，使得模型可以快速学习到一个关系类别的特征，从而对这样只有极少数样本的类别进行准确分类。下图所示是少样本关系抽取任务的一个范式，初始网络参数\\(f_θ\\)使用少量关系\\(R_i\\)的实例进行训练或微调后得到参数\\(f_{(θ_i)}\\),这组参数可以很好地用于提取对应的关系\\(R_i\\)。 少样本学习中常见的实验设置一般被称为N-way-K-shot，N-way代表分类任务中可能的类别数量，K-shot表示每个类别有K个训练数据。 2.1 关于数据集： 清华大学NLP团队2018年提出了首个大型少样本关系抽取数据集FewRel，并且在2019年更新了FewRel 2.0版本。绝大多数少样本关系抽取的工作都会在FewRel上进行评测。 FewRel 1.0数据集有100个关系类别，每个关系类别有700条训练数据，其中有80条关系的数据被公开，另外20条关系的数据则不公开。FewRel数据集是一个非常规整的数据集，标注准确，且不存在长尾问题。 TinyRel-CM数据集则是从Chinese Literature NER RE中导出的少样本关系抽取数据集，一共只有12个关系类别，共计1100条实例。 2.2 关于方法: 度量学习方法 Snell等人提出了原型网络（下图）。可以应用在少样本关系抽取任务上，作为一个Baseline。原型网络通过学习实例和关系的表示。利用最近邻思想，对新的实例进行分类。 Koch提出的孪生网络的思想则是利用CNN网络学习每一个实例的表示，并通过计算查询实例和每一个支持实例的距离来判断所属的类别。同样被应用于关系抽取任务中，如下图所示。 MLMAN[5]是目前在FewRel 1.0榜单上效果比较好的工作。采用原型网络的思想，分别计算查询实例的嵌入向量和各支持集的原型向量，取得了比较好的效果. 元学习方法: 纯元学习方法在关系抽取上的应用相对少一些，NLP任务中，仅使用少量样本来计算高维参数空间中的梯度可能会使泛化变得困难，这也限制了元学习模型的复杂性和层深度。 2.3 更多的工作： 利用度量学习思想的改进工作，可以看看这几篇工作： Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features 链接：https://dl.acm.org/doi/10.1145/3357384.3358100 Hybrid attention-based prototypical networks for noisy few-shot relation classification 链接：https://www.aaai.org/ojs/index.php/AAAI/article/view/4604 Zero-shot relation extraction via reading comprehension 链接：https://www.aclweb.org/anthology/K1 有一些工作将目光聚焦在增量关系抽取上，利用元学习解决增量关系抽取的问题取得了不错的效果，如下面几篇工作中的第三篇： Model-Agnostic Meta-Learning for Relation Classification with Limited Supervision 链接：https://www.aclweb.org/anthology/P19-1589/ MICK: A Meta-Learning Framework for Few-shot Relation Classification with Little Training Data 链接：https://arxiv.org/abs/2004.14164 Meta-Learning Improves Lifelong Relation Extraction 链接：https://www.aclweb.org/anthology/W1 2.4 对少样本关系抽取的一些思考 在少样本典型的N-way K-shot场景在真实的关系抽取场景中可能并不完全适用。实际应用场景中，每个关系类别的标注实例很可能是极度不均匀的，有着严重的长尾分布问题。如何更好地利用多出来的标注数据提升只有极少数实例类别的性能，是一个值得我们思考的问题。 少量样本或许不足以覆盖一个关系的完整语义，那如何利用好已有的知识和语料来更好地应对关系抽取的冷启动问题也值得思考。另外，最近有一些工作开始考虑从图像中抽取实体关系（如文献[4]），这是多模态知识图谱构建的核心技术之一。 此外，在实际的知识图谱构建应用场景中，图谱的构建都是一个持续地不断迭代更新的过程，这就要求关系抽取模型也能应对持续增量的场景。如何克服增量关系抽取过程中的灾难性遗忘问题，也需要我们继续去探索！ 参考资料： [1]Finn, C., Abbeel, P., &amp; Levine, S. (2017, January). Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. In ICML. [2]Ravi, S., &amp; Larochelle, H. (2016). Optimization as a model for few-shot learning. [3]赵凯琳,靳小龙,王元卓.小样本学习研究综述[J].软件学报,2021,32(02):349-369.DOI:10.13328/j.cnki.jos.006138. [4] Wang, W., Meng, W., Wang, S., Long, G., Yao, L, Qi, G., Chen, Y. (2020). [5] Ye, Z. X., &amp; Ling, Z. H. (2019, July). Multi-Level Matching and Aggregation Network for Few-Shot Relation Classification. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (pp. 2872-2881). One-Shot Learning for Long-Tail Visual Relation Detection.AAAI2020:12225-12232 少样本关系抽取技术 - 知乎 (zhihu.com)","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"},{"name":"小样本学习","slug":"深度学习基础/小样本学习","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"Tensorflow-SimpleRNN","slug":"Tensorflow-SimpleRNN","date":"2022-12-07T00:17:00.000Z","updated":"2022-12-07T11:27:04.712Z","comments":true,"path":"2022/12/07/Tensorflow-SimpleRNN/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/12/07/Tensorflow-SimpleRNN/","excerpt":"","text":"","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Tensorflow/"}],"tags":[]},{"title":"Tensorflow-Tensorboard","slug":"Tensorflow-Tensorboard","date":"2022-12-05T09:41:22.000Z","updated":"2022-12-06T03:30:15.854Z","comments":true,"path":"2022/12/05/Tensorflow-Tensorboard/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/12/05/Tensorflow-Tensorboard/","excerpt":"","text":"简介 可视化神经网络结构实例 搭建图纸 可视化训练过程 简介 tensorboard可以可视化tensorflow构造出的神经网络，需要结合浏览器使用，主要是兼容\"Google Chrome\" 除此之外，Tensorboard还可以可视化训练过程（biases变化过程）。 可视化神经网络结构实例 搭建图纸 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import tensorflow as tfimport numpy as npx_data = np.linspace(-1,1,300,dtype=np.float32)[:,np.newaxis]noise = np.random.normal(0,0.05,x_data.shape).astype(np.float32)y_data = np.square(x_data)+noise# 从输入开始## 通过 下述方式可以将xs ys包裹起来形成一个大图层with tf.name_scope(&quot;inputs&quot;) :#给输入占位命名，之后会在可视化图中显示 xs = tf.placeholder(tf.float32,[None,1],name=&quot;x_in&quot;) # ys = tf.placeholder(tf.float32,[None,1],name=&quot;y_in&quot;) ## 编辑layerdef add_layer(inputs,in_size,out_size,activation_function=None): with tf.name_scope(&quot;layer&quot;): with tf.name_scope(&quot;Weights&quot;): Weights = tf.Variable(tf.random_normal([in_size,out_size]),name=&quot;W&quot;) with tf.name_scope(&quot;Biases&quot;): Biases = tf.Variable(tf.zeros([1,out_size])+0.1,name=&quot;b&quot;) with tf.name_scope(&quot;Wx_add_b&quot;): Wx_add_b =tf.add(tf.matmul(inputs,Weights),Biases) if activation_function==None: # 使用tensor中的提供的激活函数会默认添加名称 output=Wx_add_b else: output = activation_function(Wx_add_b) return output# 实例化层l1 = add_layer(xs,1,10,tf.nn.relu)prediction = add_layer(l1,10,1,None)# loss 部分with tf.name_scope(&quot;loss&quot;): loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=1))# train 部分with tf.name_scope(&quot;train&quot;): train_step = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)# 需要使用一个tf.summary.FileWriter() 将上述绘图，保存到一个目录中，以便后续在浏览器中浏览sesssess = tf.Session()wariter=tf.summary.FileWriter(&quot;log/&quot;,sess.graph)# 最后在终端中输入如下命令# tensorboard --logdir log 通过localhost:6066 可以看到绘图： 可视化训练过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import tensorflow as tfimport numpy as np ## make up some datax_data= np.linspace(-1, 1, 300, dtype=np.float32)[:,np.newaxis]noise= np.random.normal(0, 0.05, x_data.shape).astype(np.float32)y_data= np.square(x_data) -0.5+ noisewith tf.name_scope(&quot;inputs&quot;) :#给输入占位命名，之后会在可视化图中显示 xs = tf.placeholder(tf.float32,[None,1],name=&quot;x_in&quot;) # ys = tf.placeholder(tf.float32,[None,1],name=&quot;y_in&quot;) ## 编辑layerdef add_layer(inputs,in_size,out_size,n_layer,activation_function=None): layer_name = &quot;layer%s&quot;%n_layer with tf.name_scope(layer_name): with tf.name_scope(&quot;Weights&quot;): Weights = tf.Variable(tf.random_normal([in_size,out_size]),name=&quot;W&quot;) tf.summary.histogram(layer_name+&quot;/weights&quot;,Weights) #第一个参数是图表的名称, 第二个参数是图表要记录的变量 with tf.name_scope(&quot;Biases&quot;): Biases = tf.Variable(tf.zeros([1,out_size])+0.1,name=&quot;b&quot;) tf.summary.histogram(layer_name+&quot;/biases&quot;,Biases) with tf.name_scope(&quot;Wx_add_b&quot;): Wx_add_b =tf.add(tf.matmul(inputs,Weights),Biases) if activation_function==None: # 使用tensor中的提供的激活函数会默认添加名称 output=Wx_add_b else: output = activation_function(Wx_add_b) tf.summary.histogram(layer_name+&quot;/output&quot;,output) return output# add hidden layerl1= add_layer(xs, 1, 10 ,1, activation_function=tf.nn.relu)# add output layerprediction= add_layer(l1, 10, 1,2, activation_function=None)#设置loss变化图with tf.name_scope(&quot;loss&quot;): loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=1)) tf.summary.histogram(&quot;loss&quot;,loss)# train 部分with tf.name_scope(&quot;train&quot;): train_step = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)#合并所有的训练图sess= tf.Session()merged = tf.summary.merge_all() # tensorflow &gt;= 0.12writer = tf.summary.FileWriter(&quot;log/&quot;, sess.graph) # tensorflow &gt;=0.12sess.run(tf.global_variables_initializer()) # 替换成这样就好# 训练数据for i in range(1000): sess.run(train_step, feed_dict=&#123;xs:x_data, ys:y_data&#125;) if i%50 == 0: rs = sess.run(merged,feed_dict=&#123;xs:x_data,ys:y_data&#125;) writer.add_summary(rs, i) 最后在终端中输入如下命令: tensorboard --logdir log 然后在浏览器中localhost:6006就可以看图了 参考链接： Tensorboard 可视化好帮手 1 - Tensorflow | 莫烦Python (yulizi123.github.io)","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Tensorflow/"}],"tags":[]},{"title":"Tensorflow-建造第一个神经网络","slug":"Tensorflow-建造第一个神经网络","date":"2022-12-05T06:40:11.000Z","updated":"2022-12-05T09:31:16.267Z","comments":true,"path":"2022/12/05/Tensorflow-建造第一个神经网络/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/12/05/Tensorflow-%E5%BB%BA%E9%80%A0%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"","text":"定义一个添加层 构造神经网络 结果可视化 关于优化器 定义一个添加层 在 Tensorflow 里定义一个添加层的函数可以很容易的添加神经层,为之后的添加省下不少时间. 1234567891011121314151617import tensorflow as tfdef add_layer(inputs,input_size,output_size,activation_func =None): # 一个简单的全连接层 需要定义Weights 和Biases Weights = tf.Variable(tf.random_normal([input_size,output_size])) #随机变量要比全为0好的多 Biases = tf.Variable(tf.zeros([1,output_size])+0.1) Wx_add_b = tf.matmul(inputs,Weights)+Biases # 是否需要激活函数 if activation_func==None: output = Wx_add_b else: output = activation_func(Wx_add_b) return output 构造神经网络 个人理解 就是构建好了一个计算图，然后开始训练 1234567891011121314151617181920212223242526272829303132333435363738# 导入数据import numpy as npx_data = np.linspace(-1,1,300,dtype=np.float32)[:,np.newaxis]noise = np.random.normal(0,0.05,x_data.shape).astype(np.float32)y_data = np.square(x_data)+noise# 利用站位符定义神经网络的输入xs = tf.placeholder(tf.float32,[None,1]) # None表示大小是多少都可以ys = tf.placeholder(tf.float32,[None,1])# 搭建网络## 隐藏层l1 = add_layer(xs,1,100,tf.nn.relu)## 输入层prediction = add_layer(l1,100,1,activation_func=None)#计算预测值和真实值之间的误差,对差的平方和再求平均loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=1)) # 关键的一步，如何提升模型准确性train_step = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)#使用变量时需要对其初始化init = tf.global_variables_initializer()sess = tf.Session()sess.run(init)#训练for i in range(1000): # training for j in range(3): # 简单模拟一下batch_size x = x_data[100*j:100*(j+1)] y = y_data[100*j:100*(j+1)] sess.run(train_step,feed_dict=&#123;xs:x,ys:y&#125;) if (i+1) %100 ==0: print(sess.run(loss,feed_dict=&#123;xs:x_data,ys:y_data&#125;)) 123456789100.0145048910.00593812620.00424028930.00355636680.00312227830.00284836420.0027052360.00258968420.00250186630.002452812 结果可视化 12345678910import matplotlib.pyplot as pltfig = plt.figure()ax = fig.add_subplot(1,1,1)ax.scatter(x_data,y_data)predictionvalues = sess.run(prediction,feed_dict=&#123;xs:x_data&#125;)plt.plot(x_data,predictionvalues,&quot;r-&quot;,lw=5)plt.show() 关于优化器 用的时候查吧 优化器 参考文章： Tensorflow 教程系列 | 莫烦Python (yulizi123.github.io)","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Tensorflow/"}],"tags":[]},{"title":"Tensorflow基础","slug":"Tensorflow基础","date":"2022-12-04T03:11:42.000Z","updated":"2022-12-05T02:48:26.299Z","comments":true,"path":"2022/12/04/Tensorflow基础/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/12/04/Tensorflow%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Tensorflow 计算图 简单示例： Session 会话控制 Variable 变量 Placeholder 传入值 Tensorflow 计算图 Tensorflow 首先要定义神经网络的结构, 然后再把数据放入结构当中去运算和 training. 因为TensorFlow是采用数据流图（data flow graphs）来计算, 所以首先我们得创建一个数据流流图, 然后再将我们的数据（数据以张量(tensor)的形式存在）放在数据流图中计算。节点（Nodes）在图中表示数学操作,图中的线（edges）则表示在节点间相互联系的多维数据数组, 即张量（tensor)。训练模型时tensor会不断的从数据流图中的一个节点flow到另一节点, 这就是TensorFlow名字的由来。 简单示例： 1234567891011121314151617181920212223242526272829import tensorflow as tfimport numpy as np# create datax_data = np.random.rand(100).astype(np.float32)y_data = x_data*0.1 + 0.3# model builtWeights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))biases = tf.Variable(tf.zeros([1]))y = Weights*x_data + biases# calculate lossloss = tf.reduce_mean(tf.square(y-y_data))# optimizer = tf.train.GradientDescentOptimizer(0.5)train = optimizer.minimize(loss)# 上面只是init = tf.global_variables_initializer() # 初始化之前定义的所有的 Variable ！sess = tf.Session() # 创建一个会话 后面会介绍啥是会话sess.run(init) # Very importantfor step in range(200): sess.run(train) if (step+1) % 20 == 0: print(step+1, sess.run(Weights), sess.run(biases)) 12345678910110 [0.02634814] [0.48489285]20 [0.07239345] [0.31540158]40 [0.09434778] [0.30315337]60 [0.09884276] [0.30064565]80 [0.09976308] [0.3001322]100 [0.09995149] [0.30002707]120 [0.09999008] [0.30000556]140 [0.09999797] [0.30000114]160 [0.09999958] [0.30000025]180 [0.09999991] [0.30000007]200 [0.09999991] [0.30000007] Session 会话控制 Session 是Tensorflow 为了控制,和输出文件的执行的语句。 运行 session.run() 可以获得你要得知的运算结果, 或者是你所要运算的部分。 12345678910111213141516171819202122import tensorflow as tf# create two matrixesmatrix1 = tf.constant([[3,3]])matrix2 = tf.constant([[2], [2]])product = tf.matmul(matrix1,matrix2)#因为 product 不是直接计算的步骤, 所以我们会要使用 Session 来激活 product 并得到计算结果. #有两种形式使用会话控制 Session# method 1sess = tf.Session()result = sess.run(product)print(result)sess.close()# method 2with tf.Session() as sess: result2 = sess.run(product) print(result2) 12[[12]][[12]] Variable 变量 在tensorflow中定义了某字符串是变量，它才是变量，区别于python。 定义语法： tf.Variable() 123456789101112131415161718192021import tensorflow as tfstate = tf.Variable(0,name=&quot;counter&quot;)one = tf.constant(1)#定义加法步骤(注: 没有直接计算)new_value = tf.add(state,one) # 将State 更新成 new_value update = tf.assign(state,new_value) # 需要执行一下#如果定义了 Variable 就一定要initializerinit = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for _ in range(3): sess.run(update) # 数据更新也是需要run一下的 print(sess.run(new_value)) 123234 Placeholder 传入值 placeholder是Tensorflow中的占位符，暂时储存变量。 Tensorflow 如果想要从外部传入data, 那就需要用到 tf.placeholder(), 然后以这种形式传输数据 sess.run(***, feed_dict=&#123;input: **&#125;). 123456789101112import tensorflow as tf #在 Tensorflow 中需要定义 placeholder 的 type ，一般为 float32 形式input1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)# 定义乘法运算output = tf.multiply(input1,input2)with tf.Session() as sess: print(sess.run(output,feed_dict=&#123;input1:6,input2:8&#125;)) # print(sess.run(output,feed_dict=&#123;input1:[6],input2:[8]&#125;)) # 1248.0[48.] 参考资料: Tensorflow 教程系列 | 莫烦Python (yulizi123.github.io)","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Tensorflow/"}],"tags":[]},{"title":"Pytorch-data-TensorDataset","slug":"Pytorch-data-TensorDataset","date":"2022-12-01T13:00:49.000Z","updated":"2022-12-01T13:22:49.430Z","comments":true,"path":"2022/12/01/Pytorch-data-TensorDataset/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/12/01/Pytorch-data-TensorDataset/","excerpt":"","text":"关于 TensorDataset方法的说明 TensorDataset 可以用来对 tensor 进行打包，就好像 python 中的 zip 功能。该类通过每一个 tensor 的第一个维度进行索引。因此，该类中的 tensor 第一维度必须相等。 实例： 12345678from torch.utils.data import TensorDatasetimport torcha = torch.tensor([[11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99], [11, 22, 33], [44, 55, 66], [77, 88, 99]])b = torch.tensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])train_ids = TensorDataset(a, b) print(train_ids[0:2]) 12(tensor([[11, 22, 33], [44, 55, 66]]), tensor([0, 1])) 参考文章： TensorDataset_anshiquanshu的博客-CSDN博客_tensordataset","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"Diffusion Model","slug":"Diffusion-Model","date":"2022-11-28T02:32:47.000Z","updated":"2022-11-28T12:03:15.805Z","comments":true,"path":"2022/11/28/Diffusion-Model/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/28/Diffusion-Model/","excerpt":"","text":"简介 扩散过程 定义 重参数技巧得到迭代公式 逆扩散过程 基于扩散模型的目标检测框架 类别引导问题？ 简介 扩散模型是Encoder-Decoder架构的生成模型，分为扩散阶段和逆扩散阶段。 在扩散阶段，通过不断对原始数据添加噪声，使数据从原始分布变为我们期望的分布，例如通过不断添加高斯噪声将原始数据分布变为正态分布。 在逆扩散阶段，使用神经网络将数据从正态分布恢复到原始数据分布 Diffusion model模型分为扩散过程和逆扩散过程，扩散过程通过对原始数据不断加入高斯噪音，使原始数据变为高斯分布的数据，即从\\(X_0-&gt;X_T\\)；逆扩散过程通过高斯噪声还原图片，即\\(X_T-&gt;X_0\\) 扩散过程 定义 在设定扩散过程是一个马尔可夫链的条件下，向原始信息中不断添加高斯噪声，每一步添加高斯噪声的过程是从\\(X_{t-1}-&gt;X_T\\) 于是定义公式： 表示，\\(X_{t-1}-&gt;X_T\\) 是一个以\\(\\sqrt{1-\\beta_t}x_{t-1}为均值\\)，\\(\\beta_t\\)为方差的高斯分布变换 重参数技巧得到迭代公式 重参数 \\(X_t\\)表示t时刻的数据分布 \\(Z_t\\)表示t时刻添加的高斯噪音，一般固定是均值为0方差为1的高斯分布 \\(\\sqrt{1-\\beta_t}X_{t-1}\\)表示前一时刻分布的均值 \\(\\sqrt{\\beta_t}\\)表示当前时刻分布的标准差。 \\(\\beta_t\\)是预先设定的\\(0-1\\)之间的常量，所以扩散过程是不含参的。 逆扩散过程 扩散过程是将数据噪音化，反向过程就是一个去噪的过程。逆向扩散过程中，我们将以高斯噪声 \\(T∼N(0,I)\\)作为输入，从 \\((x_{t−1}|x_t)\\) 中采样，推断并重构出真实样本。这里需注意，如果 \\(β_t\\) 足够小，\\(q(x_{t−1}|x_t)\\)的采样结果也仍为高斯分布，该值也很难评估，因此难以通过公式求解的方式，来一步步推断出原始的真实分布。这里，大佬们的想法也很直接：整个数据集已经有了，既然无法直接求解，何不尝试训练出一个模型 $p_θ $来对这些噪声的条件概率进行预测呢？既然要做预测，那标签何来？这里便是将前向传播每部生成的真实噪声记录下来作为标签，前向扩散的过程除了推断外，还包含类似该数学模型所用“数据集的构建过程”。在模型做逆向扩散时，即可对前向扩散中所产生的高斯噪声进行预测，并一步一步推断，以还原最初始的样本数据。 基于扩散模型的目标检测框架 原文链接 DiffusionDet，该框架可以直接从一组随机框中检测目标，它将目标检测制定为从噪声框到目标框的去噪扩散过程。这种从 noise-to-box 的方法不需要启发式的目标先验，也不需要可学习查询，这进一步简化了目标候选，并推动了检测 pipeline 的发展。 如下图 1 所示，该研究认为 noise-to-box 范式类似于去噪扩散模型中的 noise-to-image 过程，后者是一类基于似然的模型，通过学习到的去噪模型逐步去除图像中的噪声来生成图像。 类别引导问题？ 参考文献： Diffusion model—扩散模型_原来如此-的博客-CSDN博客_扩散模型 Diffusion Model 扩散模型-通俗易懂+代码讲解]（一） - 知乎 (zhihu.com) 港大&amp;腾讯提出DiffusionDet：第一个用于目标检测的扩散模型 (qq.com) DiffusionDet：基于扩散模型的目标检测框架 - 知乎 (zhihu.com)","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"指数移动平均（EMA）","slug":"指数移动平均（EMA）","date":"2022-11-26T08:24:52.000Z","updated":"2022-11-28T12:15:43.105Z","comments":true,"path":"2022/11/26/指数移动平均（EMA）/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/26/%E6%8C%87%E6%95%B0%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87%EF%BC%88EMA%EF%BC%89/","excerpt":"","text":"EMA定义 进一步理解\\(v_t\\) 在深度模型中的应用 关于EMA的作用 EMA定义 指数移动平均（Exponential Moving Average）也叫权重移动平均（Weighted Moving Average），是一种给予近期数据更高权重的平均方法。 假设我们有n个数据：\\([\\theta_1 ,\\theta_2,...,\\theta_n]\\) 普通的平均数： \\(\\overline{v}=\\frac1n \\sum _{i=1} ^n \\theta_i\\) EMA： \\(v_t = \\beta ·v_{t-1} + (1-\\beta)·\\theta_t\\) ，其中， \\(v_t\\)表示前\\(t\\)条的平均值 ( \\(v_0 =0\\) )， \\(\\beta\\)是加权权重值 (一般设为0.9-0.999)。 EMA 可以看成是过去 \\(1/(1-\\beta)\\)天的 \\(\\theta 值的平均\\) 如： \\(\\beta = 0.9\\) \\(1/(1-\\beta)=10\\) \\(v_t\\)大概表示前10天的平均数据 红线 \\(\\beta = 0.98\\) \\(1/(1-\\beta)=50\\) \\(v_t\\)大概表示前50天的平均数据 绿线 \\(\\beta = 0.5\\) \\(1/(1-\\beta)=2\\) 大\\(v_t\\)概表示前2天的平均数据 黄线 那么\\(\\beta\\)越大，表示考虑的时间长度越长 进一步理解\\(v_t\\) \\(v_t = \\beta ·v_{t-1} + (1-\\beta)·\\theta_t\\) 当 \\(\\beta=0.9\\)，从\\(v_{100}\\)往回写: \\[ v_{100}=0.1\\theta_{100}+0.9v_{99}\\\\ v_{99}=0.1\\theta_{98}+0.9v_{98}\\\\ ... \\] 可得: \\[ v_{100}=0.1\\theta_{100}+0.1*0.9*\\theta_{99}+0.1*(0.9)^2\\theta_{98}+.. \\] 由此可知： \\(v_(100)是\\theta_i的加权求和\\) \\(\\theta\\)前的系数相加逼近1 在深度模型中的应用 \\(v_t = \\beta ·v_{t-1} + (1-\\beta)·\\theta_t\\) \\(\\theta_t\\)：在第t次更新得到的所有参数权重。 \\(v_t\\)：第t次更新的所有参数移动平均数。 \\(\\beta\\)：权重参数。 关于EMA的作用 对于更新n次时普通的参数权重\\(\\theta_n\\): \\[ \\theta_n = \\theta_i - \\sum_{i=1}^{n-1} g_i \\\\ ,g_n 为第n次传播得到的梯度 \\] 对于更新n次时，使用EMA的参数权重\\(v_n\\) \\[ v_n = \\theta_1 -\\sum_{i=1}^{n-1}(1-\\beta^{n-i})g_i \\] 普通的参数权重相当于一直累积更新整个训练过程的梯度，使用EMA的参数权重相当于使用训练过程梯度的加权平均（刚开始的梯度权值很小）。由于刚开始训练不稳定，得到的梯度给更小的权值更为合理，所以EMA会有效。 参考资料： (43条消息) 指数移动平均（EMA）的原理及PyTorch实现_枫林扬的博客-CSDN博客_指数移动平均 (43条消息) EMA(指数移动平均)及其深度学习应用_Kmaeii的博客-CSDN博客_ema指数移动平均值","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"Python 中的特殊成员(属性和方法)","slug":"Python-call-方法","date":"2022-11-26T07:56:57.000Z","updated":"2022-11-26T12:47:18.034Z","comments":true,"path":"2022/11/26/Python-call-方法/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/26/Python-call-%E6%96%B9%E6%B3%95/","excerpt":"","text":"__call__()方法 暂无 __call__()方法 Python类中一个非常特殊的实例方法，即 call()。该方法的功能类似于在类中重载 () 运算符，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用 实例: 1234567class CLanguage: # 定义__call__方法 def __call__(self,name,add): print(&quot;调用__call__()方法&quot;,name,add)clangs = CLanguage()clangs(&quot;C语言中文网&quot;,&quot;http://c.biancheng.net&quot;) 执行结果 1调用__call__()方法 C语言中文网 http://c.biancheng.net 暂无","categories":[{"name":"Python","slug":"Python","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Python/"}],"tags":[]},{"title":"(Pytorch)nn.BCEWithLogitsLoss","slug":"Pytorch-nn-BCEWithLogitsLoss","date":"2022-11-26T07:08:59.000Z","updated":"2022-11-26T07:54:52.694Z","comments":true,"path":"2022/11/26/Pytorch-nn-BCEWithLogitsLoss/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/26/Pytorch-nn-BCEWithLogitsLoss/","excerpt":"","text":"nn.BCELoss nn.BCEWithLogitsLoss nn.BCELoss 1torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction=&#x27;mean&#x27;) 创建一个衡量目标和输入概率之间的二进制交叉熵的标准 公式 \\[ loss(x,y)= L = \\{l_1,l_2,...,l_N\\} ,\\\\ l_n = -w_n[y_n ·logx_n+(1-y_n)·log(1-x_n)] \\] N 表示batch size ，reduction可以指定模式: \\[ loss(x,y) = \\begin{cases} mean(L), &amp;if\\ reduction\\ =\\ &#39;mean&#39;\\\\ sum(L), &amp;if\\ reduction\\ =\\ &#39;sum&#39; \\end{cases} \\] 实例： 12345678import torchimport torch.nn as nnm = nn.Sigmoid() # 前面需要接 sigmoidloss = nn.BCELoss()input = torch.randn(3, requires_grad=True)target = torch.empty(3).random_(2)output = loss(m(input), target)output.backward() nn.BCEWithLogitsLoss nn.Sigmoid + nn.BCELoss 12345loss = nn.BCEWithLogitsLoss()input = torch.randn(3, requires_grad=True)target = torch.empty(3).random_(2)output = loss(input, target)output.backward()","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"迁移学习","slug":"迁移学习","date":"2022-11-21T10:15:00.000Z","updated":"2022-11-21T12:13:56.608Z","comments":true,"path":"2022/11/21/迁移学习/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/21/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"1. 什么是迁移学习 2. 迁移学习的关键 3. 迁移学习分类 3.1 基于实例的迁移 3.2 基于特征的迁移 3.3 基于共享参数的迁移 4. 深度学习和迁移学习的结合 1. 什么是迁移学习 在某些机器学习场景中，由于直接对目标域从头开始学习成本太高，因此我们期望运用已有的相关知识来辅助尽快地学习新知识。比如，已经会下中国象棋，就可以类比着来学习国际象棋；已经会编写Java程序，就可以类比着来学习C#； 迁移学习（Transfer Learning）通俗来讲就是学会举一反三的能力，通过运用已有的知识来学习新的知识，其核心是找到已有知识和新知识之间的相似性，通过这种相似性的迁移达到迁移学习的目的。 规范化定义： 给定源域 $D_s $和学习任务 $T_s $、目标域 $D_t $和学习任务 \\(T_t\\) ,迁移学习的目的是获取源域 \\(D_s\\)和学习任务 $T_s $中的知识以帮助提升目标域中的预测函数 $f_t(⋅) $的学习，其中 $D_s≠D_t $或者 \\(T_s≠T_t\\) 。 image-20221121192419440 2. 迁移学习的关键 3. 迁移学习分类 基于实例的迁移 基于特征的迁移 基于共享参数的迁移 3.1 基于实例的迁移 基于实例的迁移学习研究的是，如何从源领域中挑选出，对目标领域的训练有用的实例，比如对源领域的有标记数据实例进行有效的权重分配，让源域实例分布接近目标域的实例分布，从而在目标领域中建立一个分类精度较高的、可靠地学习模型。 因为，迁移学习中源领域与目标领域的数据分布是不一致，所以源领域中所有有标记的数据实例不一定都对目标领域有用。戴文渊等人提出的TrAdaBoost算法就是典型的基于实例的迁移。 3.2 基于特征的迁移 基于特征选择的迁移学习算法 如何找出源领域与目标领域之间共同的特征表示，然后利用这些特征进行知识迁移。 基于特征映射的迁移学习算法 如何将源领域和目标领域的数据从原始特征空间映射到新的特征空间中去。 这样，在该空间中，源领域数据与的目标领域的数据分布相同，从而可以在新的空间中，更好地利用源领域已有的有标记数据样本进行分类训练，最终对目标领域的数据进行分类测试。 3.3 基于共享参数的迁移 基于共享参数的迁移研究的是如何找到源数据和目标数据的空间模型之间的共同参数或者先验分布，从而可以通过进一步处理，达到知识迁移的目的，假设前提是，学习任务中的的每个相关模型会共享一些相同的参数或者先验分布。 4. 深度学习和迁移学习的结合 深度学习需要大量的高质量标注数据，Pre-training + fine-tuning 是现在深度学习中一个非常流行的trick，尤其是以图像领域为代表，很多时候会选择预训练的ImageNet对模型进行初始化。 参考资料: (43条消息) 迁移学习概述（Transfer Learning）_zhyuxie的博客-CSDN博客 迁移学习之——什么是迁移学习（Transfer Learning） - 知乎 (zhihu.com)","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"多通道卷积网络","slug":"多通道卷积网络","date":"2022-11-21T10:07:15.000Z","updated":"2022-11-21T10:12:49.005Z","comments":true,"path":"2022/11/21/多通道卷积网络/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/21/%E5%A4%9A%E9%80%9A%E9%81%93%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/","excerpt":"","text":"很容易理解，就放一张图吧 参考资料: (43条消息) 多通道卷积理解_A half moon的博客-CSDN博客_多通道卷积 (43条消息) 多通道图片的卷积_小小川_的博客-CSDN博客_多通道图片","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"TCN-时间卷积网络","slug":"TCN-时间卷积网络","date":"2022-11-21T08:56:49.000Z","updated":"2022-11-21T10:14:02.697Z","comments":true,"path":"2022/11/21/TCN-时间卷积网络/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/21/TCN-%E6%97%B6%E9%97%B4%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/","excerpt":"","text":"1. 引言 2. 时序卷积神经网络（TCN） 2.1 因果卷积 2.2 膨胀卷积 2.3 残差链接 3. TCN优缺点 4. 小结： 参考原文: 1. 引言 传统的卷积神经网络一般认为不太适合时序问题的建模，这主要由于其卷积核大小的限制，不能很好的抓取长时的依赖信息。 特定的卷积神经网络结构也可以达到很好的效果，比如Goolgle提出的用来做语音合成的wavenet，Facebook提出的用来做翻译的卷积神经网络 时序卷积网络（Temporal convolutional network， TCN）的提出是为了是卷积神经网络具备时序特性，与多种RNN结构相对比，发现在多种任务上TCN都能达到甚至超过RNN模型。 2. 时序卷积神经网络（TCN） 分类： 因果卷积(Causal Convolution) 膨胀卷积（Dilated Convolution） 残差链接(Residual Connections) 2.1 因果卷积 即对于上一层t时刻的值，只依赖于下一层t时刻及其之前的值。和传统的卷积神经网络的不同之处在于，因果卷积不能看到未来的数据，它是单向的结构，不是双向的。也就是说只有有了前面的因才有后面的果，是一种严格的时间约束模型，因此被成为因果卷积。 问题: 单纯的因果卷积还是存在传统卷积神经网络的问题，即对时间的建模长度受限于卷积核大小的，如果要想抓去更长的依赖关系，就需要线性的堆叠很多的层。 2.2 膨胀卷积 和传统卷积不同的是，膨胀卷积允许卷积时的输入存在间隔采样，采样率受图中的d控制。 最下面一层的d=1，表示输入时每个点都采样，中间层d=2，表示输入时每2个点采样一个作为输入。一般来讲，越高的层级使用的d的大小越大。所以，膨胀卷积使得有效窗口的大小随着层数呈指数型增长。这样卷积网络用比较少的层，就可以获得很大的感受野。 2.3 残差链接 残差链接被证明是训练深层网络的有效方法，它使得网络可以以跨层的方式传递信息。本文构建了一个残差块来代替一层的卷积。如上图所示，一个残差块包含两层的卷积和非线性映射，在每层中还加入了WeightNorm和Dropout来正则化网络。 3. TCN优缺点 优点 并行性，较之RNN，TCN可以并行处理，不需要顺序处理 感受野灵活 梯度稳定、内存低 缺点： TCN 在迁移学习方面可能没有那么强的适应能力。这是因为在不同的领域，模型预测所需要的历史信息量可能是不同的。因此，在将一个模型从一个对记忆信息需求量少的问题迁移到一个需要更长记忆的问题上时，TCN 可能会表现得很差，因为其感受野不够大。 论文中描述的TCN还是一种单向的结构，在语音识别和语音合成等任务上，纯单向的结构还是相当有用的。但是在文本中大多使用双向的结构，当然将TCN也很容易扩展成双向的结构，不使用因果卷积，使用传统的卷积结构即可。 TCN毕竟是卷积神经网络的变种，虽然使用扩展卷积可以扩大感受野，但是仍然受到限制，相比于Transformer那种可以任意长度的相关信息都可以抓取到的特性还是差了点。TCN在文本中的应用还有待检验。 4. 小结： TCN是一个CNN变体 在语音、文本等方面均有应用 参考原文: TCN-时间卷积网络_满腹的小不甘_静静-DevPress官方社区 (csdn.net)","categories":[{"name":"深度学习基础","slug":"深度学习基础","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"Transformer与LSTM优劣分析","slug":"Transformer与LSTM优劣分析","date":"2022-11-21T06:47:48.000Z","updated":"2022-11-21T12:34:09.791Z","comments":true,"path":"2022/11/21/Transformer与LSTM优劣分析/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/21/Transformer%E4%B8%8ELSTM%E4%BC%98%E5%8A%A3%E5%88%86%E6%9E%90/","excerpt":"","text":"1. 关于Transformer劣势？ Transformer缺乏对时间维度的建模，即使有Position Encoding也和LSTM这种天然的时序网络有差距； 因为缺乏时间维度的建模，稍微深层的Transformer编码器的每个位置的输出都会很相似（每层不断的在上一层基础上加权和，感性地理解一下），这一点会导致Transformer在一些要对具体位置分类的任务上表现不好； Transformer的训练trick很多。编码器的层数、attention的head数量、学习率、权重衰减等等都会严重影响模型性能，LSTM这种烦事要少很多； 大家说的Transformer效果好，大多数时候指的使用是预训练的Transformer，也就是BERT、XLNET这些预训练模型。单独用随机参数初始化的Transformer，除了Seq2Seq类模型（生成、翻译），其他领域效果特别好的少； 2. RNN劣势？ RNN结构在NLP中的优势很明显，但是也有一个很明显的缺点，就是RNN本身的序列依赖结构对于大规模并行计算来说相当的不友好，换句话说，就是RNN很难具备高效的并行计算能力。深度学习大火的原因就是因为GPU硬件环境在支持，而RNN因为先天结构的问题（T时刻的隐层状态 \\(S_t\\)还依赖 \\(T-1\\)时刻的隐层状态 \\(S_{t-1}\\)的输出，这是最能体现RNN本质特征的一点），无法充分利用硬件的并行计算能力，这是一个非常非常大的问题！ 3. 如何选？ 该部分的结论来源是：论文“Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures” 语义特征提取能力 Transformer在这方面的能力非常显著地超过RNN和CNN（在考察语义类能力的任务WSD中，Transformer超过RNN和CNN大约4-8个绝对百分点），RNN和CNN两者能力差不太多。 长距离特征捕获能力 CNN特征抽取器在这方面极为显著地弱于RNN和Transformer，Transformer微弱优于RNN模型(尤其在主语谓语距离小于13时)，但在比较远的距离上（主语谓语距离大于13），RNN微弱优于Transformer，所以综合看，可以认为Transformer和RNN在这方面能力差不太多，而CNN则显著弱于前两者。 任务综合特征抽取能力 从综合特征抽取能力角度衡量，Transformer显著强于RNN和CNN，而RNN和CNN的表现差不太多，如果一定要在这两者之间比较的话，通常CNN的表现要稍微好于RNN的效果 Paper Link Transformer统治的时代，LSTM模型并没有被代替，LSTM比Tranformer优势在哪里？ - Segmentation的回答 - 知乎 Transformer统治的时代，LSTM模型并没有被代替，LSTM比Tranformer优势在哪里？ - DengBoCong的回答 - 知乎","categories":[{"name":"transformer","slug":"transformer","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/transformer/"}],"tags":[]},{"title":"Bert中的词向量各项异性","slug":"Bert中的词向量各项异性","date":"2022-11-16T01:43:20.000Z","updated":"2022-11-28T13:49:34.264Z","comments":true,"path":"2022/11/16/Bert中的词向量各项异性/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/16/Bert%E4%B8%AD%E7%9A%84%E8%AF%8D%E5%90%91%E9%87%8F%E5%90%84%E9%A1%B9%E5%BC%82%E6%80%A7/","excerpt":"","text":"概念 各向异性(Anisotropic) 的概念在BERT-flow的文章中有明确的定义： “Anisotropic” means word embeddings occupy a narrow cone in the vector space. 翻译过来就是：“各向异性”表示词嵌入在向量空间中占据了一个狭窄的圆锥形体。 在向量空间中： 各项异性就是分布与分布方向有关系，而各项同性就是各个方向都一样，以二维空间为例： 部分学者发现，Transformer学到的词向量在空间的分布如下： Bert与GPT-2中也存在类似的情况。由上图可以知道模型学到的向量分布是各项异性的。 各项异性的缺点 各向异性就有个问题，那就是最后学到的向量都挤在一起，彼此之间计算余弦相似度都很高，并不是一个很好的表示。一个好的向量表示应该同时满足Alignment 和 uniformity，前者表示相似的向量距离应该相近，后者就表示向量在空间上应该尽量均匀，最好是各向同性的。 左图是理想的表示，右图则有各向异性的缺点。 应对方法 1. 映射为各向同性 BERT-flow的工作就是将原来的分布校准为高斯分布。标准的高斯分布就是各向同性的。 img 类似的还有whitening操作。大概流程就是根据SVD分解的结果，旋转缩放后得到一个标准正态分布。 2. 消除主成分 参见论文： A Simple but Tough-to-Beat Baseline for Sentence Embeddings All-but-the-Top: Simple and Effective Postprocessing for Word Representations 3. 正则化 参见论文： Representation Degeneration Problem in Training Natural Language Generation Models 本文选自： 作者：看图学 链接：https://www.zhihu.com/question/460991118/answer/2353153090 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"nlp","slug":"nlp","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/nlp/"},{"name":"bert","slug":"nlp/bert","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/nlp/bert/"}],"tags":[]},{"title":"Pandas-excel-数据追加","slug":"Pandas-excel-数据追加","date":"2022-11-13T09:14:00.000Z","updated":"2022-11-15T13:31:00.021Z","comments":true,"path":"2022/11/13/Pandas-excel-数据追加/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/13/Pandas-excel-%E6%95%B0%E6%8D%AE%E8%BF%BD%E5%8A%A0/","excerpt":"","text":"不同于 csv ，无法直接通过mode=\"a\"，进行追加。 具体方法: 读取要追加数据的excel文件,然后与要追加的数据组合一起保存到原文件中 12345678#--coding-- utf-8--import pandasdef append_to_excel(filepath,dataframe)-&gt;None: writer=pandas.ExcelWriter(filepath,mode=&#x27;w&#x27;)#这里的mode需要用w模式，a模式会产生新的sheet data=pandas.read_excel(writer,index_col=None,header=None) data.to_excel(writer,startrow=0,index=None,header=None,sheet_name=&#x27;sheet1&#x27;) dataframe.to_excel(writer,startrow=data.shape[0],index=None,header=None,sheet_name=&#x27;sheet1&#x27;) writer.save() 感谢： (43条消息) python pandas excel同一个sheet追加不覆盖追加数据_Demnok Lannik的博客-CSDN博客_python panada 追加sheet","categories":[{"name":"Pandas","slug":"Pandas","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pandas/"}],"tags":[]},{"title":"Pytorch-data-DataLoader使用","slug":"Pytorch-data-DataLoader使用","date":"2022-11-13T06:44:06.000Z","updated":"2023-02-10T07:34:56.115Z","comments":true,"path":"2022/11/13/Pytorch-data-DataLoader使用/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/13/Pytorch-data-DataLoader%E4%BD%BF%E7%94%A8/","excerpt":"","text":"简介 torch.utils.data.DataLoader主要是对数据进行batch的划分，除此之外，特别要注意的是输入进函数的数据一定得是可迭代的。如果是自定的数据集的话可以在定义类中用def__len__、def__getitem__定义。 使用DataLoader的好处是，可以快速的迭代数据。 示例 123456789101112131415161718192021222324252627282930313233343536373839import torchimport torch.utils.data as Datatorch.manual_seed(1) # reproducible BATCH_SIZE = 5 # 批训练的数据个数 x = torch.linspace(1, 10, 10) # x data (torch tensor)y = torch.linspace(10, 1, 10) # y data (torch tensor) # 先转换成 torch 能识别的 Datasettorch_dataset = Data.TensorDataset(x, y) # 把 dataset 放入 DataLoaderloader = Data.DataLoader( dataset=torch_dataset, # torch TensorDataset format batch_size=BATCH_SIZE, # mini batch size shuffle=True, # 要不要打乱数据 (打乱比较好) num_workers=2, # 多线程来读数据) for epoch in range(3): # 训练所有!整套!数据 3 次 for step, (batch_x, batch_y) in enumerate(loader): # 每一步 loader 释放一小批数据用来学习 # 假设这里就是你训练的地方... # 打出来一些数据 print(&quot;&#x27;Epoch: &#x27;&quot;, epoch, &quot;&#x27;| Step: &#x27;&quot;, step, &quot;&#x27;| batch x: &#x27;&quot;,batch_x.numpy(), \\ &quot;&#x27;| batch y: &#x27;&quot;, batch_y.numpy()) &quot;&quot;&quot;Epoch: 0 | Step: 0 | batch x: [ 6. 7. 2. 3. 1.] | batch y: [ 5. 4. 9. 8. 10.]Epoch: 0 | Step: 1 | batch x: [ 9. 10. 4. 8. 5.] | batch y: [ 2. 1. 7. 3. 6.]Epoch: 1 | Step: 0 | batch x: [ 3. 4. 2. 9. 10.] | batch y: [ 8. 7. 9. 2. 1.]Epoch: 1 | Step: 1 | batch x: [ 1. 7. 8. 5. 6.] | batch y: [ 10. 4. 3. 6. 5.]Epoch: 2 | Step: 0 | batch x: [ 3. 9. 2. 6. 7.] | batch y: [ 8. 2. 9. 5. 4.]Epoch: 2 | Step: 1 | batch x: [ 10. 4. 8. 1. 5.] | batch y: [ 1. 7. 3. 10. 6.]&quot;&quot;&quot;“”如果改变batch大小每次迭代数据不够batch,则函数就会把剩下的数据输出。“” PyTorch DataLoader工作原理可视化 (qq.com) (51条消息) pytorch中collate_fn函数的使用&amp;如何向collate_fn函数传参_XJTU-Qidong的博客-CSDN博客_pytorch collate_fn","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"对比学习","slug":"对比学习","date":"2022-11-09T01:23:17.000Z","updated":"2022-11-15T13:30:10.687Z","comments":true,"path":"2022/11/09/对比学习/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/09/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"对比学习属于无监督或者自监督学习 目前，对比学习貌似处于“无明确定义、有指导原则”的状态，它的指导原则是：通过自动构造相似实例和不相似实例，要求习得一个表示学习模型，通过这个模型，使得相似的实例在投影空间中比较接近，而不相似的实例在投影空间中距离比较远。而如何构造相似实例，以及不相似实例，如何构造能够遵循上述指导原则的表示学习模型结构，以及如何防止模型坍塌(Model Collapse)，这几个点是其中的关键。 目前出现的一些方法： 从防止模型坍塌的不同方法角度，我们可大致把现有方法划分为：基于负例的对比学习方法、基于对比聚类的方法、基于不对称网络结构的方法，以及基于冗余消除损失函数的方法。","categories":[{"name":"contrastive","slug":"contrastive","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/contrastive/"}],"tags":[]},{"title":"Pytorch-nn-Embedding","slug":"Pytorch-nn-Embedding","date":"2022-11-04T02:51:22.000Z","updated":"2022-11-15T13:32:52.492Z","comments":true,"path":"2022/11/04/Pytorch-nn-Embedding/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/04/Pytorch-nn-Embedding/","excerpt":"","text":"简述 123torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None) 其为一个简单的存储固定大小的词典的嵌入向量的查找表，意思就是说，给一个编号，嵌入层就能返回这个编号对应的嵌入向量，嵌入向量反映了各个编号代表的符号之间的语义关系。 输入为一个编号列表，输出为对应的符号嵌入向量列表。 参数说明 num_embeddings (python:int) – 词典的大小尺寸，比如总共出现5000个词，那就输入5000。此时index为（0-4999） embedding_dim (python:int)– 嵌入向量的维度，即用多少维来表示一个符号。 padding_idx (python:int, optional) – 填充id，比如，输入长度为100，但是每次的句子长度并不一样，后面就需要用统一的数字填充，而这里就是指定这个数字，这样，网络在遇到填充id时，就不会计算其与其它符号的相关性。（初始化为0） max_norm (python:float, optional) – 最大范数，如果嵌入向量的范数超过了这个界限，就要进行再归一化 norm_type (python:float, optional) – 指定利用什么范数计算，并用于对比max_norm，默认为2范数。 scale_grad_by_freq (boolean, optional) – 根据单词在mini-batch中出现的频率，对梯度进行放缩。默认为False. sparse (bool, optional) – 若为True,则与权重矩阵相关的梯度转变为稀疏张量。 实例 123456789101112131415161718192021222324&gt;&gt;&gt; # an Embedding module containing 10 tensors of size 3&gt;&gt;&gt; embedding = nn.Embedding(10, 3)&gt;&gt;&gt; # a batch of 2 samples of 4 indices each&gt;&gt;&gt; input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])&gt;&gt;&gt; embedding(input)tensor([[[-0.0251, -1.6902, 0.7172], [-0.6431, 0.0748, 0.6969], [ 1.4970, 1.3448, -0.9685], [-0.3677, -2.7265, -0.1685]], [[ 1.4970, 1.3448, -0.9685], [ 0.4362, -0.4004, 0.9400], [-0.6431, 0.0748, 0.6969], [ 0.9124, -2.3616, 1.1151]]]) &gt;&gt;&gt; # example with padding_idx&gt;&gt;&gt; embedding = nn.Embedding(10, 3, padding_idx=0)&gt;&gt;&gt; input = torch.LongTensor([[0,2,0,5]])&gt;&gt;&gt; embedding(input)tensor([[[ 0.0000, 0.0000, 0.0000], [ 0.1535, -2.0309, 0.9315], [ 0.0000, 0.0000, 0.0000], [-0.1655, 0.9897, 0.0635]]])","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"(Pytorch)中的一些基本方法","slug":"Pytorch-中的一些基本方法","date":"2022-10-28T03:18:51.000Z","updated":"2023-04-06T03:45:33.838Z","comments":true,"path":"2022/10/28/Pytorch-中的一些基本方法/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/10/28/Pytorch-%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95/","excerpt":"1. torch.chunk方法 2. torch.cumsum方法 3. torch.cat方法 4. torch.stack方法 5. torch.max方法 6. squeeze与unsqueezef方法 7. torch.split方法 8. tensor.expand() 方法 9. tensor.transpose()方法","text":"1. torch.chunk方法 2. torch.cumsum方法 3. torch.cat方法 4. torch.stack方法 5. torch.max方法 6. squeeze与unsqueezef方法 7. torch.split方法 8. tensor.expand() 方法 9. tensor.transpose()方法 1. torch.chunk方法 1Tensor.chunk(chunks,dim=0) # 可以参考torch.chunk() torch.chunk tensor (Tensor) – the tensor to split chunks (int) - number of chunks to return（分割的块数） dim (int) - dimension along which to split the tensor（沿着哪个轴分块） 实例： 实例 2. torch.cumsum方法 返回 输入张量指定维度累加和 1torch.cumsum(input, dim, *, dtype=None, out=None) → Tensor 参数： input (Tensor) 输入张量 dim (int) 操作的维度 计算原理: cumsum 计算原理 3. torch.cat方法 在给定维数中连接给定序列的 seq 张量。所有张量必须具有相同的形状(连接维数除外)或为空。 1torch.cat(tensors, dim=0, *, out=None) → Tensor 实例： 12345678910111213141516&gt;&gt;&gt; x = torch.randn(2, 3)&gt;&gt;&gt; xtensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 0)tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 1)tensor([[ 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497]]) 4. torch.stack方法 沿着一个新的维数连接一系列张量。 所有张量的大小必须相同。 1torch.stack(tensors, dim=0, *, out=None) → Tensor # 插入了一个维度 实例： 1234567891011import torchl = 4tag = torch.FloatTensor(l, l, 2).fill_(0)tag1 = torch.FloatTensor(l, l, 2).fill_(5)tag2 = torch.FloatTensor(l, l, 2).fill_(2)tags = torch.stack([tag,tag1,tag2],dim=0)display(tags.shape)tags = torch.stack([tag,tag1,tag2],dim=1)tags.shape output: 12torch.Size([3, 4, 4, 2])torch.Size([4, 3, 4, 2]) 5. torch.max方法 方式一： 1torch.max(input) → Tensor 返回所有元素的最大值 实例： 12345&gt;&gt;&gt; a = torch.randn(1, 3)&gt;&gt;&gt; atensor([[ 0.6763, 0.7445, -2.2369]])&gt;&gt;&gt; torch.max(a)tensor(0.7445) 方式二： 1torch.max(input, dim, keepdim=False, *, out=None) 返回一个命名元组(values, indexes)，其中values是给定维度dim中输入张量的每一行的最大值。而indexes是找到的每个最大值的索引位置(argmax)。 实例： 12345678&gt;&gt;&gt; a = torch.randn(4, 4)&gt;&gt;&gt; atensor([[-1.2360, -0.2942, -0.1222, 0.8475], [ 1.1949, -1.1127, -2.2379, -0.6702], [ 1.5717, -0.9207, 0.1297, -1.8768], [-0.6172, 1.0036, -0.6060, -0.2432]])&gt;&gt;&gt; torch.max(a, 1)torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1])) 方式二，个人理解： ​ 给定一个张量 t 和维度d，设 t 的维度为 x*y*z 最后的返回值values（仅表示思路 ）: 12345d = 0 # 举例output = torch.zeros(y,z)for i in range(y): for j in range(z): output[i][j] = max(t[:][i][j]) 6. squeeze与unsqueezef方法 给tensor删除或者添加维度为1的维度 squeeze() 方法 在pytorch中，用torch.squeeze()函数或者tensor的自身成员函数squeeze()去除维度为1的维度。 使用示例: 12345678x = torch.randn(3,1,2,4,1)print(x.shape)x_ = x.squeeze() # 默认删除所大小为1 的维度print(x_.shape)y = torch.squeeze(x,dim=1) # 指定维度print(y.shape)z = torch.squeeze(x,dim=2) # dim=2 维度不是1 无法去除 但不会报错print(z.shape) 1234torch.Size([3, 1, 2, 4, 1])torch.Size([3, 2, 4])torch.Size([3, 2, 4, 1])torch.Size([3, 1, 2, 4, 1]) unsqueeze() 方法 在pytorch中，用自带的torch.unsqueeze()和tensor的成员函数unsqueeze()可以为tensor添加维度为1的维度 1234e = torch.unsqueeze(x, dim=0) # 在第一维度添加维度print(e.shape)f = x.unsqueeze(dim=0)print(f.shape) 12torch.Size([1, 3, 1, 4, 1, 2])torch.Size([1, 3, 1, 4, 1, 2]) 7. torch.split方法 按块大小拆分张量 1torch.split(tensor, split_size_or_sections, dim = 0) tensor 为待拆分张量 dim 指定张量拆分的所在维度，即在第几维对张量进行拆分 split_size_or_sections 表示在 dim 维度拆分张量时每一块在该维度的尺寸大小 (int)，或各块尺寸大小的列表 (list) 指定每一块的尺寸大小后，如果在该维度无法整除，则最后一块会取余数，尺寸较小一些 如：长度为 10 的张量，按单位长度 3 拆分，则前三块长度为 3，最后一块长度为 1 函数返回：所有拆分后的张量所组成的 tuple 函数并不会改变原 tensor 实例： 12345a = torch.arange(10).reshape(5,2)b,c = torch.split(a,1,dim=-1)print(a)print(b.squeeze())print(c.squeeze()) 1234567tensor([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])tensor([0, 2, 4, 6, 8])tensor([1, 3, 5, 7, 9]) 8. tensor.expand() 方法 tensor.expand()函数可以将维度值包含 1 的Tensor（如：torch.Size([1, n])或者torch.Size([n, 1])）的维度进行扩展。其具体的扩展规则如下： 只能对维度值包含 1 的张量Tensor进行扩展，即：Tensor的size必须满足：torch.Size([1, n])或者 torch.Size([n, 1])。 只能对维度值等于 1 的那个维度进行扩展，无需扩展的维度务必保持维度值不变，或者置为-1，否则，报错。（简言之，只要是单维度均可进行扩展，但是若非单维度会报错。） 扩展的Tensor不会分配新的内存，只是原来的基础上创建新的视图并返回； 新扩展维度的取值范围为：− 1 以 及 [ 1 , + ∞ ] 区 间 内 的 任 意 整 数 -1以及[1, +∞]区间内的任意整数−1以及[1,+∞]区间内的任意整数，例如：将 torch.Size([1, n]) 扩展为torch.Size([m, n])时，新扩展维度 m 的可能取值为-1，或者 m ≥ 1的任意整数； 只能对张量Tensor进行维度扩展，而不能降维；否则，报错。 tensor通过.expand()函数扩展某一维度后，tensor自身不会发生变化。 123456789101112131415161718import torcha = torch.tensor([[2], [3], [4]]) # 创建size为3行1列的张量print(&quot;a:\\n&quot;, a)print(a.size())&gt;&gt;&gt;a: tensor([[2], [3], [4]])torch.Size([3, 1])# （1）将torch.Size([3, 1])扩展为torch.Size([3, 2])a.expand(3,2)&gt;&gt;&gt;tensor([[2, 2], [3, 3], [4, 4]]) 9. tensor.transpose()方法 该函数可以交换tensor的任意两个维度，但是该函数一次只有两个参数，即一次只能交换两个维度 1234import torchx = torch.randn(8, 3, 5, 4)y = x.transpose(1,2) # 交换第二与第三维度print(y.shape) 1torch.Size([8, 5, 3, 4])","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"(Pytorch) nn.Dropout","slug":"Pytorch-nn-Dropout","date":"2022-10-27T09:04:16.000Z","updated":"2022-11-15T13:32:14.476Z","comments":true,"path":"2022/10/27/Pytorch-nn-Dropout/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/10/27/Pytorch-nn-Dropout/","excerpt":"","text":"目的： 为了防止过拟合 Dropout防止过拟合 具体用法 1nn.Dropout(0.2) #表示每个输入的神经元有 0.2的概率被设为0 从下图中也可以看到，其他的数 除了（1-0.3） 补充说明: Dropout 只能用于训练部分，不可用于测试 一般用在全连接神经网络映射层之后 还可用于将Tensor中的部分值设为0 如上图","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"my first blog","slug":"my-first-blog","date":"2022-10-24T01:14:45.000Z","updated":"2022-11-20T01:28:36.846Z","comments":true,"path":"2022/10/24/my-first-blog/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/10/24/my-first-blog/","excerpt":"","text":"我的第一个博客 你好世界！ 博客模板： fi3ework/hexo-theme-archer: 🎯 A smart and modern theme for Hexo. (github.com) memaid测试 graph LR 1(CIR-Lab) --> 1.1(实验室共享文件) -->小组A学习资料 1.1--> 小组B学习资料 1.1--> 研究生课程学习与考试资料等 1.1--> 文件互传 style 1.1 fill:#0f0,stroke:#333,stroke-width:4px 1 --> 1.2(实验室项目资料) -->项目A资料 style 1.2 fill:#f91,stroke:#333,stroke-width:4px 1.2--> 软著资料 1.2--> 专利资料 1.2--> 论文资料 latex公式测试 \\[ \\begin{equation} \\left\\{ \\begin{array}{lr} x=\\dfrac{3\\pi}{2}(1+2t)\\cos(\\dfrac{3\\pi}{2}(1+2t)), &amp; \\\\ y=s, &amp; 0 \\leq s \\leq L,|t| \\leq1. \\\\ z=\\dfrac{3\\pi}{2}(1+2t)\\sin(\\dfrac{3\\pi}{2}(1+2t)), &amp; \\end{array} \\right. \\end{equation} \\]","categories":[],"tags":[]}],"categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"},{"name":"numpy","slug":"numpy","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/numpy/"},{"name":"Python","slug":"Python","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Python/"},{"name":"深度学习基础","slug":"深度学习基础","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"},{"name":"小样本学习","slug":"深度学习基础/小样本学习","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Tensorflow/"},{"name":"transformer","slug":"transformer","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/transformer/"},{"name":"nlp","slug":"nlp","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/nlp/"},{"name":"bert","slug":"nlp/bert","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/nlp/bert/"},{"name":"Pandas","slug":"Pandas","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pandas/"},{"name":"contrastive","slug":"contrastive","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/contrastive/"}],"tags":[]}