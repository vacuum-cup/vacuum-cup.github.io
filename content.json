{"meta":{"title":"Hexo","subtitle":"","description":"","author":"xnf","url":"https://github.com/vacuum-cup/vacuum-cup.github.io","root":"/"},"pages":[{"title":"[404]","date":"2022-11-15T13:26:07.499Z","updated":"2022-11-15T13:26:07.499Z","comments":true,"path":"404.html","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/404.html","excerpt":"","text":"é¡µé¢èµ°ä¸¢äº†~"},{"title":"About","date":"2022-11-15T07:16:27.000Z","updated":"2022-11-15T13:24:00.378Z","comments":true,"path":"about/index.html","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/about/index.html","excerpt":"","text":"éšå§“åŸ‹åçš„å°è„‘æ–§"}],"posts":[{"title":"Pandas-excel-æ•°æ®è¿½åŠ ","slug":"Pandas-excel-æ•°æ®è¿½åŠ ","date":"2022-11-13T09:14:00.000Z","updated":"2022-11-15T13:31:00.021Z","comments":true,"path":"2022/11/13/Pandas-excel-æ•°æ®è¿½åŠ /","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/13/Pandas-excel-%E6%95%B0%E6%8D%AE%E8%BF%BD%E5%8A%A0/","excerpt":"","text":"ä¸åŒäº csv ï¼Œæ— æ³•ç›´æ¥é€šè¿‡mode=â€aâ€ï¼Œè¿›è¡Œè¿½åŠ ã€‚ å…·ä½“æ–¹æ³•: è¯»å–è¦è¿½åŠ æ•°æ®çš„excelæ–‡ä»¶,ç„¶åä¸è¦è¿½åŠ çš„æ•°æ®ç»„åˆä¸€èµ·ä¿å­˜åˆ°åŸæ–‡ä»¶ä¸­ 12345678#--coding-- utf-8--import pandasdef append_to_excel(filepath,dataframe)-&gt;None: writer=pandas.ExcelWriter(filepath,mode=&#x27;w&#x27;)#è¿™é‡Œçš„modeéœ€è¦ç”¨wæ¨¡å¼ï¼Œaæ¨¡å¼ä¼šäº§ç”Ÿæ–°çš„sheet data=pandas.read_excel(writer,index_col=None,header=None) data.to_excel(writer,startrow=0,index=None,header=None,sheet_name=&#x27;sheet1&#x27;) dataframe.to_excel(writer,startrow=data.shape[0],index=None,header=None,sheet_name=&#x27;sheet1&#x27;) writer.save() æ„Ÿè°¢ï¼š (43æ¡æ¶ˆæ¯) python pandas excelåŒä¸€ä¸ªsheetè¿½åŠ ä¸è¦†ç›–è¿½åŠ æ•°æ®_Demnok Lannikçš„åšå®¢-CSDNåšå®¢_python panada è¿½åŠ sheet","categories":[{"name":"Pandas","slug":"Pandas","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pandas/"}],"tags":[]},{"title":"Pytorch-data-DataLoaderä½¿ç”¨","slug":"Pytorch-data-DataLoaderä½¿ç”¨","date":"2022-11-13T06:44:06.000Z","updated":"2022-11-15T13:31:27.438Z","comments":true,"path":"2022/11/13/Pytorch-data-DataLoaderä½¿ç”¨/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/13/Pytorch-data-DataLoader%E4%BD%BF%E7%94%A8/","excerpt":"","text":"ç®€ä»‹ torch.utils.data.DataLoaderä¸»è¦æ˜¯å¯¹æ•°æ®è¿›è¡Œbatchçš„åˆ’åˆ†ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œç‰¹åˆ«è¦æ³¨æ„çš„æ˜¯è¾“å…¥è¿›å‡½æ•°çš„æ•°æ®ä¸€å®šå¾—æ˜¯å¯è¿­ä»£çš„ã€‚å¦‚æœæ˜¯è‡ªå®šçš„æ•°æ®é›†çš„è¯å¯ä»¥åœ¨å®šä¹‰ç±»ä¸­ç”¨def__len__ã€def__getitem__å®šä¹‰ã€‚ ä½¿ç”¨DataLoaderçš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥å¿«é€Ÿçš„è¿­ä»£æ•°æ®ã€‚ ç¤ºä¾‹ 123456789101112131415161718192021222324252627282930313233343536373839import torchimport torch.utils.data as Datatorch.manual_seed(1) # reproducible BATCH_SIZE = 5 # æ‰¹è®­ç»ƒçš„æ•°æ®ä¸ªæ•° x = torch.linspace(1, 10, 10) # x data (torch tensor)y = torch.linspace(10, 1, 10) # y data (torch tensor) # å…ˆè½¬æ¢æˆ torch èƒ½è¯†åˆ«çš„ Datasettorch_dataset = Data.TensorDataset(x, y) # æŠŠ dataset æ”¾å…¥ DataLoaderloader = Data.DataLoader( dataset=torch_dataset, # torch TensorDataset format batch_size=BATCH_SIZE, # mini batch size shuffle=True, # è¦ä¸è¦æ‰“ä¹±æ•°æ® (æ‰“ä¹±æ¯”è¾ƒå¥½) num_workers=2, # å¤šçº¿ç¨‹æ¥è¯»æ•°æ®) for epoch in range(3): # è®­ç»ƒæ‰€æœ‰!æ•´å¥—!æ•°æ® 3 æ¬¡ for step, (batch_x, batch_y) in enumerate(loader): # æ¯ä¸€æ­¥ loader é‡Šæ”¾ä¸€å°æ‰¹æ•°æ®ç”¨æ¥å­¦ä¹  # å‡è®¾è¿™é‡Œå°±æ˜¯ä½ è®­ç»ƒçš„åœ°æ–¹... # æ‰“å‡ºæ¥ä¸€äº›æ•°æ® print(&quot;&#x27;Epoch: &#x27;&quot;, epoch, &quot;&#x27;| Step: &#x27;&quot;, step, &quot;&#x27;| batch x: &#x27;&quot;,batch_x.numpy(), \\ &quot;&#x27;| batch y: &#x27;&quot;, batch_y.numpy()) &quot;&quot;&quot;Epoch: 0 | Step: 0 | batch x: [ 6. 7. 2. 3. 1.] | batch y: [ 5. 4. 9. 8. 10.]Epoch: 0 | Step: 1 | batch x: [ 9. 10. 4. 8. 5.] | batch y: [ 2. 1. 7. 3. 6.]Epoch: 1 | Step: 0 | batch x: [ 3. 4. 2. 9. 10.] | batch y: [ 8. 7. 9. 2. 1.]Epoch: 1 | Step: 1 | batch x: [ 1. 7. 8. 5. 6.] | batch y: [ 10. 4. 3. 6. 5.]Epoch: 2 | Step: 0 | batch x: [ 3. 9. 2. 6. 7.] | batch y: [ 8. 2. 9. 5. 4.]Epoch: 2 | Step: 1 | batch x: [ 10. 4. 8. 1. 5.] | batch y: [ 1. 7. 3. 10. 6.]&quot;&quot;&quot;â€œâ€å¦‚æœæ”¹å˜batchå¤§å°æ¯æ¬¡è¿­ä»£æ•°æ®ä¸å¤Ÿbatch,åˆ™å‡½æ•°å°±ä¼šæŠŠå‰©ä¸‹çš„æ•°æ®è¾“å‡ºã€‚â€œâ€","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"å¯¹æ¯”å­¦ä¹ ","slug":"å¯¹æ¯”å­¦ä¹ ","date":"2022-11-09T01:23:17.000Z","updated":"2022-11-15T13:30:10.687Z","comments":true,"path":"2022/11/09/å¯¹æ¯”å­¦ä¹ /","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/09/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"å¯¹æ¯”å­¦ä¹ å±äºæ— ç›‘ç£æˆ–è€…è‡ªç›‘ç£å­¦ä¹  ç›®å‰ï¼Œå¯¹æ¯”å­¦ä¹ è²Œä¼¼å¤„äºâ€œæ— æ˜ç¡®å®šä¹‰ã€æœ‰æŒ‡å¯¼åŸåˆ™â€çš„çŠ¶æ€ï¼Œå®ƒçš„æŒ‡å¯¼åŸåˆ™æ˜¯ï¼šé€šè¿‡è‡ªåŠ¨æ„é€ ç›¸ä¼¼å®ä¾‹å’Œä¸ç›¸ä¼¼å®ä¾‹ï¼Œè¦æ±‚ä¹ å¾—ä¸€ä¸ªè¡¨ç¤ºå­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡è¿™ä¸ªæ¨¡å‹ï¼Œä½¿å¾—ç›¸ä¼¼çš„å®ä¾‹åœ¨æŠ•å½±ç©ºé—´ä¸­æ¯”è¾ƒæ¥è¿‘ï¼Œè€Œä¸ç›¸ä¼¼çš„å®ä¾‹åœ¨æŠ•å½±ç©ºé—´ä¸­è·ç¦»æ¯”è¾ƒè¿œã€‚è€Œå¦‚ä½•æ„é€ ç›¸ä¼¼å®ä¾‹ï¼Œä»¥åŠä¸ç›¸ä¼¼å®ä¾‹ï¼Œå¦‚ä½•æ„é€ èƒ½å¤Ÿéµå¾ªä¸Šè¿°æŒ‡å¯¼åŸåˆ™çš„è¡¨ç¤ºå­¦ä¹ æ¨¡å‹ç»“æ„ï¼Œä»¥åŠå¦‚ä½•é˜²æ­¢æ¨¡å‹åå¡Œ(Model Collapse)ï¼Œè¿™å‡ ä¸ªç‚¹æ˜¯å…¶ä¸­çš„å…³é”®ã€‚ ç›®å‰å‡ºç°çš„ä¸€äº›æ–¹æ³•ï¼š ä»é˜²æ­¢æ¨¡å‹åå¡Œçš„ä¸åŒæ–¹æ³•è§’åº¦ï¼Œæˆ‘ä»¬å¯å¤§è‡´æŠŠç°æœ‰æ–¹æ³•åˆ’åˆ†ä¸ºï¼šåŸºäºè´Ÿä¾‹çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ã€åŸºäºå¯¹æ¯”èšç±»çš„æ–¹æ³•ã€åŸºäºä¸å¯¹ç§°ç½‘ç»œç»“æ„çš„æ–¹æ³•ï¼Œä»¥åŠåŸºäºå†—ä½™æ¶ˆé™¤æŸå¤±å‡½æ•°çš„æ–¹æ³•ã€‚","categories":[{"name":"contrastive","slug":"contrastive","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/contrastive/"}],"tags":[]},{"title":"Pytorch-nn-Embedding","slug":"Pytorch-nn-Embedding","date":"2022-11-04T02:51:22.000Z","updated":"2022-11-15T13:32:52.492Z","comments":true,"path":"2022/11/04/Pytorch-nn-Embedding/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/11/04/Pytorch-nn-Embedding/","excerpt":"","text":"ç®€è¿° 123torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None) å…¶ä¸ºä¸€ä¸ªç®€å•çš„å­˜å‚¨å›ºå®šå¤§å°çš„è¯å…¸çš„åµŒå…¥å‘é‡çš„æŸ¥æ‰¾è¡¨ï¼Œæ„æ€å°±æ˜¯è¯´ï¼Œç»™ä¸€ä¸ªç¼–å·ï¼ŒåµŒå…¥å±‚å°±èƒ½è¿”å›è¿™ä¸ªç¼–å·å¯¹åº”çš„åµŒå…¥å‘é‡ï¼ŒåµŒå…¥å‘é‡åæ˜ äº†å„ä¸ªç¼–å·ä»£è¡¨çš„ç¬¦å·ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ã€‚ è¾“å…¥ä¸ºä¸€ä¸ªç¼–å·åˆ—è¡¨ï¼Œè¾“å‡ºä¸ºå¯¹åº”çš„ç¬¦å·åµŒå…¥å‘é‡åˆ—è¡¨ã€‚ å‚æ•°è¯´æ˜ num_embeddings (python:int) â€“ è¯å…¸çš„å¤§å°å°ºå¯¸ï¼Œæ¯”å¦‚æ€»å…±å‡ºç°5000ä¸ªè¯ï¼Œé‚£å°±è¾“å…¥5000ã€‚æ­¤æ—¶indexä¸ºï¼ˆ0-4999ï¼‰ embedding_dim (python:int)â€“ åµŒå…¥å‘é‡çš„ç»´åº¦ï¼Œå³ç”¨å¤šå°‘ç»´æ¥è¡¨ç¤ºä¸€ä¸ªç¬¦å·ã€‚ padding_idx (python:int, optional) â€“ å¡«å……idï¼Œæ¯”å¦‚ï¼Œè¾“å…¥é•¿åº¦ä¸º100ï¼Œä½†æ˜¯æ¯æ¬¡çš„å¥å­é•¿åº¦å¹¶ä¸ä¸€æ ·ï¼Œåé¢å°±éœ€è¦ç”¨ç»Ÿä¸€çš„æ•°å­—å¡«å……ï¼Œè€Œè¿™é‡Œå°±æ˜¯æŒ‡å®šè¿™ä¸ªæ•°å­—ï¼Œè¿™æ ·ï¼Œç½‘ç»œåœ¨é‡åˆ°å¡«å……idæ—¶ï¼Œå°±ä¸ä¼šè®¡ç®—å…¶ä¸å…¶å®ƒç¬¦å·çš„ç›¸å…³æ€§ã€‚ï¼ˆåˆå§‹åŒ–ä¸º0ï¼‰ max_norm (python:float, optional) â€“ æœ€å¤§èŒƒæ•°ï¼Œå¦‚æœåµŒå…¥å‘é‡çš„èŒƒæ•°è¶…è¿‡äº†è¿™ä¸ªç•Œé™ï¼Œå°±è¦è¿›è¡Œå†å½’ä¸€åŒ– norm_type (python:float, optional) â€“ æŒ‡å®šåˆ©ç”¨ä»€ä¹ˆèŒƒæ•°è®¡ç®—ï¼Œå¹¶ç”¨äºå¯¹æ¯”max_normï¼Œé»˜è®¤ä¸º2èŒƒæ•°ã€‚ scale_grad_by_freq (boolean, optional) â€“ æ ¹æ®å•è¯åœ¨mini-batchä¸­å‡ºç°çš„é¢‘ç‡ï¼Œå¯¹æ¢¯åº¦è¿›è¡Œæ”¾ç¼©ã€‚é»˜è®¤ä¸ºFalse. sparse (bool, optional) â€“ è‹¥ä¸ºTrue,åˆ™ä¸æƒé‡çŸ©é˜µç›¸å…³çš„æ¢¯åº¦è½¬å˜ä¸ºç¨€ç–å¼ é‡ã€‚ å®ä¾‹ 123456789101112131415161718192021222324&gt;&gt;&gt; # an Embedding module containing 10 tensors of size 3&gt;&gt;&gt; embedding = nn.Embedding(10, 3)&gt;&gt;&gt; # a batch of 2 samples of 4 indices each&gt;&gt;&gt; input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])&gt;&gt;&gt; embedding(input)tensor([[[-0.0251, -1.6902, 0.7172], [-0.6431, 0.0748, 0.6969], [ 1.4970, 1.3448, -0.9685], [-0.3677, -2.7265, -0.1685]], [[ 1.4970, 1.3448, -0.9685], [ 0.4362, -0.4004, 0.9400], [-0.6431, 0.0748, 0.6969], [ 0.9124, -2.3616, 1.1151]]]) &gt;&gt;&gt; # example with padding_idx&gt;&gt;&gt; embedding = nn.Embedding(10, 3, padding_idx=0)&gt;&gt;&gt; input = torch.LongTensor([[0,2,0,5]])&gt;&gt;&gt; embedding(input)tensor([[[ 0.0000, 0.0000, 0.0000], [ 0.1535, -2.0309, 0.9315], [ 0.0000, 0.0000, 0.0000], [-0.1655, 0.9897, 0.0635]]])","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"(Pytorch)ä¸­çš„ä¸€äº›åŸºæœ¬æ–¹æ³•","slug":"Pytorch-ä¸­çš„ä¸€äº›åŸºæœ¬æ–¹æ³•","date":"2022-10-28T03:18:51.000Z","updated":"2022-11-15T13:33:39.965Z","comments":true,"path":"2022/10/28/Pytorch-ä¸­çš„ä¸€äº›åŸºæœ¬æ–¹æ³•/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/10/28/Pytorch-%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95/","excerpt":"1. torch.chunkæ–¹æ³• 2. torch.cumsumæ–¹æ³• 3. torch.catæ–¹æ³• 4. torch.stackæ–¹æ³• 5. torch.maxæ–¹æ³•","text":"1. torch.chunkæ–¹æ³• 2. torch.cumsumæ–¹æ³• 3. torch.catæ–¹æ³• 4. torch.stackæ–¹æ³• 5. torch.maxæ–¹æ³• 1. torch.chunkæ–¹æ³•1Tensor.chunk(chunks,dim=0) # å¯ä»¥å‚è€ƒtorch.chunk() torch.chunk tensor (Tensor) â€“ the tensor to split chunks (int) - number of chunks to returnï¼ˆåˆ†å‰²çš„å—æ•°ï¼‰ dim (int) - dimension along which to split the tensorï¼ˆæ²¿ç€å“ªä¸ªè½´åˆ†å—ï¼‰ å®ä¾‹ï¼š 2. torch.cumsumæ–¹æ³•è¿”å› è¾“å…¥å¼ é‡æŒ‡å®šç»´åº¦ç´¯åŠ å’Œ 1torch.cumsum(input, dim, *, dtype=None, out=None) â†’ Tensor å‚æ•°ï¼š input (Tensor) è¾“å…¥å¼ é‡ dim (int) æ“ä½œçš„ç»´åº¦ è®¡ç®—åŸç†: 3. torch.catæ–¹æ³•åœ¨ç»™å®šç»´æ•°ä¸­è¿æ¥ç»™å®šåºåˆ—çš„ seq å¼ é‡ã€‚æ‰€æœ‰å¼ é‡å¿…é¡»å…·æœ‰ç›¸åŒçš„å½¢çŠ¶(è¿æ¥ç»´æ•°é™¤å¤–)æˆ–ä¸ºç©ºã€‚ 1torch.cat(tensors, dim=0, *, out=None) â†’ Tensor å®ä¾‹ï¼š 12345678910111213141516&gt;&gt;&gt; x = torch.randn(2, 3)&gt;&gt;&gt; xtensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 0)tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]])&gt;&gt;&gt; torch.cat((x, x, x), 1)tensor([[ 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497]]) 4. torch.stackæ–¹æ³•æ²¿ç€ä¸€ä¸ªæ–°çš„ç»´æ•°è¿æ¥ä¸€ç³»åˆ—å¼ é‡ã€‚ æ‰€æœ‰å¼ é‡çš„å¤§å°å¿…é¡»ç›¸åŒã€‚ 1torch.stack(tensors, dim=0, *, out=None) â†’ Tensor # æ’å…¥äº†ä¸€ä¸ªç»´åº¦ å®ä¾‹ï¼š 1234567891011import torchl = 4tag = torch.FloatTensor(l, l, 2).fill_(0)tag1 = torch.FloatTensor(l, l, 2).fill_(5)tag2 = torch.FloatTensor(l, l, 2).fill_(2)tags = torch.stack([tag,tag1,tag2],dim=0)display(tags.shape)tags = torch.stack([tag,tag1,tag2],dim=1)tags.shape output: 12torch.Size([3, 4, 4, 2])torch.Size([4, 3, 4, 2]) 5. torch.maxæ–¹æ³•æ–¹å¼ä¸€ï¼š 1torch.max(input) â†’ Tensor è¿”å›æ‰€æœ‰å…ƒç´ çš„æœ€å¤§å€¼ å®ä¾‹ï¼š 12345&gt;&gt;&gt; a = torch.randn(1, 3)&gt;&gt;&gt; atensor([[ 0.6763, 0.7445, -2.2369]])&gt;&gt;&gt; torch.max(a)tensor(0.7445) æ–¹å¼äºŒï¼š 1torch.max(input, dim, keepdim=False, *, out=None) è¿”å›ä¸€ä¸ªå‘½åå…ƒç»„(values, indexes)ï¼Œå…¶ä¸­valuesæ˜¯ç»™å®šç»´åº¦dimä¸­è¾“å…¥å¼ é‡çš„æ¯ä¸€è¡Œçš„æœ€å¤§å€¼ã€‚è€Œindexesæ˜¯æ‰¾åˆ°çš„æ¯ä¸ªæœ€å¤§å€¼çš„ç´¢å¼•ä½ç½®(argmax)ã€‚ å®ä¾‹ï¼š 12345678&gt;&gt;&gt; a = torch.randn(4, 4)&gt;&gt;&gt; atensor([[-1.2360, -0.2942, -0.1222, 0.8475], [ 1.1949, -1.1127, -2.2379, -0.6702], [ 1.5717, -0.9207, 0.1297, -1.8768], [-0.6172, 1.0036, -0.6060, -0.2432]])&gt;&gt;&gt; torch.max(a, 1)torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1])) æ–¹å¼äºŒï¼Œä¸ªäººç†è§£ï¼š â€‹ ç»™å®šä¸€ä¸ªå¼ é‡ t å’Œç»´åº¦dï¼Œè®¾ t çš„ç»´åº¦ä¸º x*y*z æœ€åçš„è¿”å›å€¼valuesï¼ˆä»…è¡¨ç¤ºæ€è·¯ ï¼‰: 12345d = 0 # ä¸¾ä¾‹output = torch.zeros(y,z)for i in range(y): for j in range(z): output[i][j] = max(t[:][i][j])","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"(Pytorch) nn.Dropout","slug":"Pytorch-nn-Dropout","date":"2022-10-27T09:04:16.000Z","updated":"2022-11-15T13:32:14.476Z","comments":true,"path":"2022/10/27/Pytorch-nn-Dropout/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/10/27/Pytorch-nn-Dropout/","excerpt":"","text":"ç›®çš„ï¼š ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆ å…·ä½“ç”¨æ³• 1nn.Dropout(0.2) #è¡¨ç¤ºæ¯ä¸ªè¾“å…¥çš„ç¥ç»å…ƒæœ‰ 0.2çš„æ¦‚ç‡è¢«è®¾ä¸º0 ä»ä¸‹å›¾ä¸­ä¹Ÿå¯ä»¥çœ‹åˆ°ï¼Œå…¶ä»–çš„æ•° é™¤äº†ï¼ˆ1-0.3ï¼‰ è¡¥å……è¯´æ˜: Dropout åªèƒ½ç”¨äºè®­ç»ƒéƒ¨åˆ†ï¼Œä¸å¯ç”¨äºæµ‹è¯• ä¸€èˆ¬ç”¨åœ¨å…¨è¿æ¥ç¥ç»ç½‘ç»œæ˜ å°„å±‚ä¹‹å è¿˜å¯ç”¨äºå°†Tensorä¸­çš„éƒ¨åˆ†å€¼è®¾ä¸º0 å¦‚ä¸Šå›¾","categories":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"}],"tags":[]},{"title":"my first blog","slug":"my-first-blog","date":"2022-10-24T01:14:45.000Z","updated":"2022-11-15T13:29:34.675Z","comments":true,"path":"2022/10/24/my-first-blog/","link":"","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/2022/10/24/my-first-blog/","excerpt":"","text":"æˆ‘çš„ç¬¬ä¸€ä¸ªåšå®¢ ä½ å¥½ä¸–ç•Œï¼ åšå®¢æ¨¡æ¿ï¼š fi3ework/hexo-theme-archer: ğŸ¯ A smart and modern theme for Hexo. (github.com)","categories":[],"tags":[]}],"categories":[{"name":"Pandas","slug":"Pandas","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pandas/"},{"name":"Pytorch","slug":"Pytorch","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/Pytorch/"},{"name":"contrastive","slug":"contrastive","permalink":"https://github.com/vacuum-cup/vacuum-cup.github.io/categories/contrastive/"}],"tags":[]}